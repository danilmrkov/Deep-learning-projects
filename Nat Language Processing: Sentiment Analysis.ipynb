{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project - construct a model, which will classify website reviews into Bad or Good \n",
    "Size of data sample - ~2 mln Amazon reviews in fastText format (kaggle dataset) \n",
    "I contructed three models on sentiment classification - fastText, XGBoost and RNN LSTM models.\n",
    "As a target metric I chose ROC AUC.\n",
    "\n",
    "The following results were achieved:\n",
    "1. fastText: 90,91%\n",
    "2. XGBoost: 85,91%\n",
    "3. RNN LSTM: 91,97%\n",
    "\n",
    "In conlusion, within the constraints of this project, I choose RNN LSTM model as the best due to the highest ROC AUC value.\n",
    "\n",
    "Thoughts on improvement: RNN LSTM model could perform even better, if it was trained on the whole dataset (if only I had more computing power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import fasttext\n",
    "import string\n",
    "import re\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('fastText-0.9.1.zip', 'r') as fastText:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   fastText.extractall()\n",
    "\n",
    "with ZipFile('train.ft.txt.bz2.zip', 'r') as train:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   train.extractall()\n",
    "    \n",
    "with ZipFile('test.ft.txt.bz2.zip', 'r') as test:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   test.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test.ft.txt', 'r', encoding ='utf-8')\n",
    "X_test = []\n",
    "for i in f: \n",
    "    X_test.append(i[11:])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test.ft.txt', 'r', encoding ='utf-8')\n",
    "y_test = []\n",
    "for i in f: \n",
    "    if i[:10] == '__label__1':\n",
    "        y_test.append(0)\n",
    "    else:\n",
    "        y_test.append(1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train.ft.txt', 'r', encoding ='utf-8')\n",
    "X_train = []\n",
    "for i in f: \n",
    "    X_train.append(i[11:])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train.ft.txt', 'r', encoding ='utf-8')\n",
    "y_train = []\n",
    "for i in f: \n",
    "    if i[:10] == '__label__1':\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        y_train.append(1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building fastText classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.train_supervised('train.ft.txt')\n",
    "fasttext_model.save_model(\"fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.load_model(\"fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    pred = fasttext_model.predict(X_test[i].rstrip())\n",
    "    if pred[0] == ('__label__1',):\n",
    "        fasttext_pred.append(0)\n",
    "    else:\n",
    "        fasttext_pred.append(1)\n",
    "        \n",
    "with open('fasttext_pred', 'wb') as f:\n",
    "     pickle.dump(fasttext_pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fasttext_pred', 'rb') as f:\n",
    "     fasttext_pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_auc = roc_auc_score(y_test, fasttext_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.90911\n"
     ]
    }
   ],
   "source": [
    "print (\"SCORE:\", fasttext_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building TFIDF + XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenizerr(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=Tokenizerr, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model.fit(XGB_train, y_train)\n",
    "\n",
    "XGB_model.save_model(\"XGB_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model.load_model(\"XGB_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pred = XGB_model.predict(test)\n",
    "\n",
    "with open('XGB_pred', 'wb') as f:\n",
    "     pickle.dump(XGB_pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('XGB_pred', 'rb') as f:\n",
    "     XGB_pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_auc = roc_auc_score(y_test, XGB_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.85914\n"
     ]
    }
   ],
   "source": [
    "print (\"SCORE:\", XGB_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building RNN LSTM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since I have limited computing power, I had to take twice less of the given dataset\n",
    "train_data_len = int(len(X_train)*0.5)\n",
    "test_data_len = int(len(X_test)*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = X_train[:train_data_len]\n",
    "train_labels = y_train[:train_data_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = X_test[:test_data_len]\n",
    "test_labels = y_test[:test_data_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train len: '+ str(len(train_labels)))\n",
    "print('Test len: '+ str(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(list(zip(train_text, train_labels)))\n",
    "train_data.columns = {'text', 'labels'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(list(zip(test_text, test_labels)))\n",
    "test_data.columns = {'text', 'labels'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = ''\n",
    "    text_nopunct = re.sub('['+string.punctuation+']', '', text)\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Text_Clean'] = train_data['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Text_Clean'] = test_data['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = [word_tokenize(sen) for sen in train_data.Text_Clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = [word_tokenize(sen) for sen in test_data.Text_Clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_token(tokens): \n",
    "    return [w.lower() for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_train_tokens = [lower_token(token) for token in train_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_test_tokens = [lower_token(token) for token in test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(tokens): \n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_words = [removeStopWords(sen) for sen in lower_train_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_words = [removeStopWords(sen) for sen in lower_test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Text_Final'] = [' '.join(sen) for sen in filtered_train_words]\n",
    "train_data['tokens'] = filtered_train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Text_Final'] = [' '.join(sen) for sen in filtered_test_words]\n",
    "test_data['tokens'] = filtered_test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "\n",
    "for l in train_data.labels:\n",
    "    if l == 0:\n",
    "        pos.append(0)\n",
    "        neg.append(1)\n",
    "    elif l == 1:\n",
    "        pos.append(1)\n",
    "        neg.append(0)\n",
    "        \n",
    "train_data['Pos']= pos\n",
    "train_data['Neg']= neg\n",
    "\n",
    "train_data = train_data[['Text_Final', 'tokens', 'labels', 'Pos', 'Neg']]\n",
    "train_data.head()\n",
    "\n",
    "with open('train_data', 'wb') as f:\n",
    "     pickle.dump(train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "\n",
    "for l in test_data.labels:\n",
    "    if l == 0:\n",
    "        pos.append(0)\n",
    "        neg.append(1)\n",
    "    elif l == 1:\n",
    "        pos.append(1)\n",
    "        neg.append(0)\n",
    "        \n",
    "test_data['Pos']= pos\n",
    "test_data['Neg']= neg\n",
    "\n",
    "test_data = test_data[['Text_Final', 'tokens', 'labels', 'Pos', 'Neg']]\n",
    "test_data.head()\n",
    "\n",
    "with open('test_data', 'wb') as f:\n",
    "     pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data', 'rb') as f:\n",
    "     train_data = pickle.load(f)\n",
    "        \n",
    "with open('test_data', 'rb') as f:\n",
    "     test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Text_Final  \\\n",
      "0  great cd lovely pat one great voices generatio...   \n",
      "1  one best game music soundtracks game didnt rea...   \n",
      "2  batteries died within year bought charger jul ...   \n",
      "3  works fine maha energy better check maha energ...   \n",
      "4  great nonaudiophile reviewed quite bit combo p...   \n",
      "\n",
      "                                              tokens  labels  Pos  Neg  \n",
      "0  [great, cd, lovely, pat, one, great, voices, g...       1    1    0  \n",
      "1  [one, best, game, music, soundtracks, game, di...       1    1    0  \n",
      "2  [batteries, died, within, year, bought, charge...       0    0    1  \n",
      "3  [works, fine, maha, energy, better, check, mah...       1    1    0  \n",
      "4  [great, nonaudiophile, reviewed, quite, bit, c...       1    1    0  \n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Text_Final  \\\n",
      "0  stuning even nongamer sound track beautiful pa...   \n",
      "1  best soundtrack ever anything im reading lot r...   \n",
      "2  amazing soundtrack favorite music time hands i...   \n",
      "3  excellent soundtrack truly like soundtrack enj...   \n",
      "4  remember pull jaw floor hearing youve played g...   \n",
      "\n",
      "                                              tokens  labels  Pos  Neg  \n",
      "0  [stuning, even, nongamer, sound, track, beauti...       1    1    0  \n",
      "1  [best, soundtrack, ever, anything, im, reading...       1    1    0  \n",
      "2  [amazing, soundtrack, favorite, music, time, h...       1    1    0  \n",
      "3  [excellent, soundtrack, truly, like, soundtrac...       1    1    0  \n",
      "4  [remember, pull, jaw, floor, hearing, youve, p...       1    1    0  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_words = [word for tokens in train_data[\"tokens\"] for word in tokens]\n",
    "training_sentence_lengths = [len(tokens) for tokens in train_data[\"tokens\"]]\n",
    "training_vocab = sorted(list(set(all_training_words)))\n",
    "\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(training_vocab)))\n",
    "print(\"Max sentence length is %s\" % max(training_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_words = [word for tokens in test_data[\"tokens\"] for word in tokens]\n",
    "test_sentence_lengths = [len(tokens) for tokens in test_data[\"tokens\"]]\n",
    "test_vocab = sorted(list(set(all_test_words)))\n",
    "\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_test_words), len(test_vocab)))\n",
    "print(\"Max sentence length is %s\" % max(test_sentence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize and Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(training_vocab), lower=True, char_level=False, oov_token=True)\n",
    "tokenizer.fit_on_texts(train_data[\"Text_Final\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_index = tokenizer.word_index\n",
    "print(\"Found %s unique tokens.\" % len(train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(train_data[\"Text_Final\"].tolist())\n",
    "train_rnn_data = pad_sequences(training_sequences, maxlen=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_rnn_data', 'wb') as f:\n",
    "     pickle.dump(train_rnn_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_data[\"Text_Final\"].tolist())\n",
    "test_rnn_data = pad_sequences(test_sequences, maxlen=150)\n",
    "\n",
    "with open('test_rnn_data', 'wb') as f:\n",
    "     pickle.dump(test_rnn_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define RNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Pos', 'Neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_rnn_data', 'rb') as f:\n",
    "     x_tr = pickle.load(f)\n",
    "        \n",
    "y_tr = train_data[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 128)          256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 650,754\n",
      "Trainable params: 650,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "max_fatures = 2000\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(max_fatures, embed_dim, input_length = x_tr.shape[1]))\n",
    "rnn_model.add(SpatialDropout1D(0.4))\n",
    "\n",
    "rnn_model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "rnn_model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "rnn_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a file with RNN weights\n",
    "filename = \"rnn_model.hdf5\"\n",
    "filepath = \"rnn_model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = rnn_model.fit(x_tr, y_tr, epochs=20, batch_size=512, callbacks=callbacks)\n",
    "\n",
    "with open('hist', 'wb') as f:\n",
    "     pickle.dump(hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "with open('hist', 'rb') as f:\n",
    "     hist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pre-trained weights\n",
    "rnn_model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss values\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('test_rnn_data', 'rb') as f:\n",
    "     x_te = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te = test_data[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_pred = rnn_model.predict(x_te, batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_pred_label = []\n",
    "for i in rnn_pred:\n",
    "    if i[0]>i[1]:\n",
    "        rnn_pred_label.append(1)\n",
    "    else:\n",
    "        rnn_pred_label.append(0)\n",
    "        \n",
    "with open('rnn_pred_label', 'wb') as f:\n",
    "     pickle.dump(rnn_pred_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rnn_pred_label', 'rb') as f:\n",
    "     rnn_pred_label = pickle.load(f)\n",
    "        \n",
    "y_label = test_data['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_auc = roc_auc_score(y_label, rnn_pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.9197318438897866\n"
     ]
    }
   ],
   "source": [
    "print (\"SCORE:\", rnn_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
