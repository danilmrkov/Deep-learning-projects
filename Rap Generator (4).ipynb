{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project - construct a model, which will generate random verses based on the learned song lyrics.\n",
    "\n",
    "As a base model, LSTM recurrent neural network was chosen.\n",
    "\n",
    "Data sample - 20 song lyrics of the russian artist \"Oxxxymiron\" downloaded from Genius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lyricsgenius\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "#For MSE models\n",
    "import nltk\n",
    "from nltk.util import bigrams, trigrams\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer, TreebankWordDetokenizer\n",
    "from nltk.lm import MLE\n",
    "\n",
    "\n",
    "#For RNN model\n",
    "import sys\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapper = 'Oxxxymiron'\n",
    "num_songs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lyricsgenius.Genius(\"jOoA2dCGT_F8pHJJmmd3HgXotfZlbpDr2Dwd9QTA2v122saEfQ3S-RDCu_xd76u7\")\n",
    "\n",
    "genius.skip_non_songs = True\n",
    "genius.verbose = False\n",
    "genius.remove_section_headers = True\n",
    "genius.excluded_terms = [\"(Remix)\", \"(Live)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of chosen songs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Город под подошвой (City Under the Sole)', 'Oxxxymiron'), ('«Где нас нет» (”On the Other Side”)', 'Oxxxymiron'), ('До зимы (Before Winter)', 'Oxxxymiron'), ('Неваляшка (Tumbler Toy)', 'Oxxxymiron'), ('В книге всё было по-другому (4 раунд 17ib) (The Book Had It Different)', 'Oxxxymiron'), ('Переплетено (Interlaced)', 'Oxxxymiron'), ('Тентакли (Tentacles)', 'Oxxxymiron'), ('Восточный Мордор (East Mordor)', 'Oxxxymiron'), ('Песенка Гремлина (Gremlin’s Song)', 'Oxxxymiron'), ('Признаки Жизни (Signs of Life)', 'Oxxxymiron'), ('Детектор лжи (Lie Detector)', 'Oxxxymiron'), ('Башня из слоновой кости (Ivory Tower)', 'Oxxxymiron'), ('Пролив Дрейка (Drake Passage)', 'Oxxxymiron'), ('Биполярочка (Bipolarochka)', 'Oxxxymiron'), ('Девочка Пиздец (Fucked Up Girl)', 'Oxxxymiron'), ('Последний звонок (Last Call)', 'Oxxxymiron'), ('Всего лишь писатель (Just a Writer)', 'Oxxxymiron'), ('Привет со дна  (Hello from the Bottom)', 'Oxxxymiron'), ('Не от мира сего (Not of This World)', 'Oxxxymiron'), ('Больше Бена (Bigga Than Ben)', 'Oxxxymiron')]\n"
     ]
    }
   ],
   "source": [
    "artist = genius.search_artist(rapper, max_songs=num_songs)\n",
    "print(artist.songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = []\n",
    "for i in range(len(artist.songs)):\n",
    "    song = [artist.songs[i].lyrics]\n",
    "    lyrics.append(song)\n",
    "    \n",
    "with open(\"oxxxymiron_lyrics.txt\", \"wb\") as fp:\n",
    "    pickle.dump(lyrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpickling our songs\n",
    "with open(\"oxxxymiron_lyrics.txt\", \"rb\") as fp:   \n",
    "    lyrics = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(lyrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the song lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sino hora sancta morta\\nSino hora sancta morta\\nSino hora sancta morta\\n\\nТам, где нас нет — горит невиданный рассвет\\nГде нас нет — море и рубиновый закат\\nГде нас нет — лес, как малахитовый браслет\\nГде нас нет, на Лебединых островах\\nГде нас нет, услышь меня и вытащи из омута\\nВеди в мой вымышленный город, вымощенный золотом\\nВо сне я вижу дали иноземные\\nГде милосердие правит, где берега кисельные\\n\\nЭй, йоу\\n«Ну-ка, слёзы вытер!\\nТо ли дело их сын, сразу видно, что он лидер»\\n«Слышишь, если спросят, то ты ничего не видел»\\n«Ай, он весь в отца, из него ничего не выйдет»\\n«Кто ж её не знает-то, всему двору сосала»\\n«Это что такое? Руки! Я кому сказала?»\\n«Всё разворовали, а бывал непобедимым»\\n«Ваш ребёнок замкнут и не ладит с коллективом»\\n«Марш в детский сад!» «Дружный класс». «Дважды два»\\n«Раз на раз, баш на баш». «Чё, зассал? Не пацан?»\\n«Тока глянь на себя, тут фингал, там синяк\\nХулиган! Стыдоба! Как ты смел, кем ты стал?»\\n«Мой-то? Да всё в облаках, как в детстве, витает»\\n«Ты ничем не лучше других, чудес не бывает»\\n«С нею? Да без шансов, он же пугалище с виду!»\\n«Хули ты всё умничаешь, сука, ты, чё, пидор?»\\n«На, сделай пару тяг — стены полетят\\nЧё, ништяк? По шестьдесят, бери сейчас»\\n«Тихий час». «Твои друзья — десять негритят»\\n«Все пиздят». «Скажи, где взял?» «Наперекосяк»\\n«Строгача!» «Как вышел, и каждое лето квасит»\\n«Сожалеем, но у нас всё так же нет вакансий»\\n«Как ты был неблагодарный, так жизнь сломал мне»\\n«На могильном камне пусть выбьют как-нибудь пошикарней»\\n\\nГде нас нет — горит невиданный рассвет\\nГде нас нет — море и рубиновый закат\\nГде нас нет — лес, как малахитовый браслет\\nГде нас нет, на Лебединых островах\\nГде нас нет, услышь меня и вытащи из омута\\nПусти в мой вымышленный город, вымощенный золотом\\nВо тьме я вижу дали иноземные\\nГде милосердие правит, где берега кисельные\\n\\n«Ты ж моя принцесса!»\\n«Ваша цель: выжать всё из её учебного процесса\\nМы в Женеву на месяц, не жалейте их, профессор»\\n«Младшая будет красавица, а эта так, в довесок»\\n«Сядьте прямо! Тут обеденный стол, юная леди!»\\n«Что за ветер в голове, что за тон и манеры эти?»\\n«Мне тут напели, кто-то в кресло вице-мэра метит?»\\n«Постеснялся бы, хотя б, своим блядям звонить при детях!»\\n«Завтра важный этап: частный пансионат\\nЕё нрав исправит, как высококлассный остеопат\\nРаз так страсти кипят, её враз тут остепенят!»\\n«Почему про отца твердят, что он властный социопат?»\\n«Гляньте-ка, вон та самая, новенькая, любуйтесь»\\n«Погоди, дитя, после школы, пока побудь здесь»\\n«Пастор поцеловал? Лазал под сарафан?»\\n«Не сопротивляйся, дитя, все дела во славу творца!»\\n«Сам не тиран и деспот, но надо знать своё место\\nА ты непутёвая недотёпа с самого детства\\nЯ даю на роскошь, новшества — тебе недаром!\\nЭта тварь из отбросов общества тебе не пара!»\\n«Съешь их, добавишь к серой рутине цветов, оттенков»\\n«Эксклюзивный реабилитационный центр»\\n«Как с настроением у нас?» «К выздоровлению\\nВместо поздравлений пусть вышлют как-нибудь поскромнее»\\n\\nГде нас нет — горит невиданный рассвет\\nГде нас нет — море и рубиновый закат\\nГде нас нет — лес, как малахитовый браслет\\nГде нас нет, на Лебединых островах\\nГде нас нет, услышь меня и вытащи из омута\\nПусти в мой вымышленный город, вымощенный золотом\\nВо тьме я вижу дали иноземные\\nГде милосердие правит и свет над берегами\\nГде нас нет — горит невиданный рассвет\\nГде нас нет — море и рубиновый закат\\nГде нас нет — лес, как малахитовый браслет\\nГде нас нет, на Лебединых островах\\nГде нас нет, услышь меня и вытащи из омута\\nВеди в мой вымышленный город, вымощенный золотом\\nВо тьме я вижу дали иноземные\\nГде милосердие правит и свет над берегами\\n\\nГде нас нет...']\n"
     ]
    }
   ],
   "source": [
    "print(lyrics[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_lyrics = lyrics\n",
    "bad_chars = [';', ':', '!', '*', 'n', ',', '.', '\"', \"'\", '(', ')', '?', '—', '\\\\', '[', ']', '»', '«']\n",
    "\n",
    "for i in clear_lyrics:\n",
    "    for char in bad_chars:\n",
    "        clear_lyrics = str(clear_lyrics).replace(char,' ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a function to tokenize & filter input data\n",
    "def tokenize_words(input): \n",
    "    #Initiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    \n",
    "    #Filter some words if they are in nltk stop list\n",
    "    filtered = filter(lambda token: token not in stopwords.words('russian'), tokens)\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess our input data and make tokens\n",
    "processed_inputs = tokenize_words(clear_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дон волга течёт котомку плечо боль груди тайничок открытый фомкой ключом сколько миль ещё перелет ко\n"
     ]
    }
   ],
   "source": [
    "print(processed_inputs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since NN requires numbers, but not text characters, convert the characters in our input to numbers\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 39672\n",
      "Total vocab: 72\n"
     ]
    }
   ],
   "source": [
    "#For futher data preparation, calculate the length of our input and vocabulary\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "\n",
    "print (\"Total number of characters:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define how long an individual sequence (one complete mapping of inputs characters as integers) to be\n",
    "seq_length = 100\n",
    "\n",
    "#Make empty lists to store our input and output data\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through inputs - start at the beginning and go until we hit the final character we can create a sequence out of\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    \n",
    "    #Define input and output sequences\n",
    "    #Input is the current character plus desired sequence length\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "\n",
    "    #Output sequence is the initial character plus total sequence length\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "\n",
    "    #Convert list of characters to integers and add the values to our lists\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 39572\n"
     ]
    }
   ],
   "source": [
    "#Total number of sequences\n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform it to numpy array for our NN\n",
    "X = np.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "\n",
    "#Make the numbers float for activation function being able to interpret them as probabilities\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode our data\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing RNN LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct stacked LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For our callback create a file with RNN weights\n",
    "filename = \"RNN_weights.hdf5\"\n",
    "filepath = \"RNN_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set callback function to save the best weights\n",
    "callbacks = [ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile RNN model on default adam optimizer and track categorical cross-entropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "39572/39572 [==============================] - 51s 1ms/step - loss: 3.7964\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.79637, saving model to RNN_weights.hdf5\n",
      "Epoch 2/500\n",
      "39572/39572 [==============================] - 52s 1ms/step - loss: 3.1574\n",
      "\n",
      "Epoch 00002: loss improved from 3.79637 to 3.15739, saving model to RNN_weights.hdf5\n",
      "Epoch 3/500\n",
      "39572/39572 [==============================] - 54s 1ms/step - loss: 3.0069\n",
      "\n",
      "Epoch 00003: loss improved from 3.15739 to 3.00692, saving model to RNN_weights.hdf5\n",
      "Epoch 4/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 2.9289\n",
      "\n",
      "Epoch 00004: loss improved from 3.00692 to 2.92886, saving model to RNN_weights.hdf5\n",
      "Epoch 5/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.8899\n",
      "\n",
      "Epoch 00005: loss improved from 2.92886 to 2.88994, saving model to RNN_weights.hdf5\n",
      "Epoch 6/500\n",
      "39572/39572 [==============================] - 74s 2ms/step - loss: 2.8608\n",
      "\n",
      "Epoch 00006: loss improved from 2.88994 to 2.86079, saving model to RNN_weights.hdf5\n",
      "Epoch 7/500\n",
      "39572/39572 [==============================] - 62s 2ms/step - loss: 2.8387\n",
      "\n",
      "Epoch 00007: loss improved from 2.86079 to 2.83870, saving model to RNN_weights.hdf5\n",
      "Epoch 8/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 2.8160\n",
      "\n",
      "Epoch 00008: loss improved from 2.83870 to 2.81604, saving model to RNN_weights.hdf5\n",
      "Epoch 9/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.7928\n",
      "\n",
      "Epoch 00009: loss improved from 2.81604 to 2.79276, saving model to RNN_weights.hdf5\n",
      "Epoch 10/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 2.7717\n",
      "\n",
      "Epoch 00010: loss improved from 2.79276 to 2.77167, saving model to RNN_weights.hdf5\n",
      "Epoch 11/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.7518\n",
      "\n",
      "Epoch 00011: loss improved from 2.77167 to 2.75183, saving model to RNN_weights.hdf5\n",
      "Epoch 12/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 2.7314\n",
      "\n",
      "Epoch 00012: loss improved from 2.75183 to 2.73143, saving model to RNN_weights.hdf5\n",
      "Epoch 13/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.7072\n",
      "\n",
      "Epoch 00013: loss improved from 2.73143 to 2.70715, saving model to RNN_weights.hdf5\n",
      "Epoch 14/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 2.6769\n",
      "\n",
      "Epoch 00014: loss improved from 2.70715 to 2.67685, saving model to RNN_weights.hdf5\n",
      "Epoch 15/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.6469\n",
      "\n",
      "Epoch 00015: loss improved from 2.67685 to 2.64690, saving model to RNN_weights.hdf5\n",
      "Epoch 16/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 2.6096\n",
      "\n",
      "Epoch 00016: loss improved from 2.64690 to 2.60958, saving model to RNN_weights.hdf5\n",
      "Epoch 17/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.5781\n",
      "\n",
      "Epoch 00017: loss improved from 2.60958 to 2.57813, saving model to RNN_weights.hdf5\n",
      "Epoch 18/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.5485\n",
      "\n",
      "Epoch 00018: loss improved from 2.57813 to 2.54851, saving model to RNN_weights.hdf5\n",
      "Epoch 19/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.5123\n",
      "\n",
      "Epoch 00019: loss improved from 2.54851 to 2.51235, saving model to RNN_weights.hdf5\n",
      "Epoch 20/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.4812\n",
      "\n",
      "Epoch 00020: loss improved from 2.51235 to 2.48115, saving model to RNN_weights.hdf5\n",
      "Epoch 21/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.4405\n",
      "\n",
      "Epoch 00021: loss improved from 2.48115 to 2.44048, saving model to RNN_weights.hdf5\n",
      "Epoch 22/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 2.3995\n",
      "\n",
      "Epoch 00022: loss improved from 2.44048 to 2.39952, saving model to RNN_weights.hdf5\n",
      "Epoch 23/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 2.3544\n",
      "\n",
      "Epoch 00023: loss improved from 2.39952 to 2.35436, saving model to RNN_weights.hdf5\n",
      "Epoch 24/500\n",
      "39572/39572 [==============================] - 61s 2ms/step - loss: 2.3253\n",
      "\n",
      "Epoch 00024: loss improved from 2.35436 to 2.32529, saving model to RNN_weights.hdf5\n",
      "Epoch 25/500\n",
      "39572/39572 [==============================] - 64s 2ms/step - loss: 2.2886\n",
      "\n",
      "Epoch 00025: loss improved from 2.32529 to 2.28862, saving model to RNN_weights.hdf5\n",
      "Epoch 26/500\n",
      "39572/39572 [==============================] - 65s 2ms/step - loss: 2.2412\n",
      "\n",
      "Epoch 00026: loss improved from 2.28862 to 2.24124, saving model to RNN_weights.hdf5\n",
      "Epoch 27/500\n",
      "39572/39572 [==============================] - 60s 2ms/step - loss: 2.2133\n",
      "\n",
      "Epoch 00027: loss improved from 2.24124 to 2.21334, saving model to RNN_weights.hdf5\n",
      "Epoch 28/500\n",
      "39572/39572 [==============================] - 63s 2ms/step - loss: 2.1760\n",
      "\n",
      "Epoch 00028: loss improved from 2.21334 to 2.17600, saving model to RNN_weights.hdf5\n",
      "Epoch 29/500\n",
      "39572/39572 [==============================] - 64s 2ms/step - loss: 2.1394\n",
      "\n",
      "Epoch 00029: loss improved from 2.17600 to 2.13939, saving model to RNN_weights.hdf5\n",
      "Epoch 30/500\n",
      "39572/39572 [==============================] - 65s 2ms/step - loss: 2.1017\n",
      "\n",
      "Epoch 00030: loss improved from 2.13939 to 2.10166, saving model to RNN_weights.hdf5\n",
      "Epoch 31/500\n",
      "39572/39572 [==============================] - 64s 2ms/step - loss: 2.0654\n",
      "\n",
      "Epoch 00031: loss improved from 2.10166 to 2.06541, saving model to RNN_weights.hdf5\n",
      "Epoch 32/500\n",
      "39572/39572 [==============================] - 64s 2ms/step - loss: 2.0341\n",
      "\n",
      "Epoch 00032: loss improved from 2.06541 to 2.03413, saving model to RNN_weights.hdf5\n",
      "Epoch 33/500\n",
      "39572/39572 [==============================] - 68s 2ms/step - loss: 2.0037\n",
      "\n",
      "Epoch 00033: loss improved from 2.03413 to 2.00368, saving model to RNN_weights.hdf5\n",
      "Epoch 34/500\n",
      "39572/39572 [==============================] - 62s 2ms/step - loss: 1.9787\n",
      "\n",
      "Epoch 00034: loss improved from 2.00368 to 1.97873, saving model to RNN_weights.hdf5\n",
      "Epoch 35/500\n",
      "39572/39572 [==============================] - 62s 2ms/step - loss: 1.9501\n",
      "\n",
      "Epoch 00035: loss improved from 1.97873 to 1.95006, saving model to RNN_weights.hdf5\n",
      "Epoch 36/500\n",
      "39572/39572 [==============================] - 69s 2ms/step - loss: 1.9120\n",
      "\n",
      "Epoch 00036: loss improved from 1.95006 to 1.91201, saving model to RNN_weights.hdf5\n",
      "Epoch 37/500\n",
      "39572/39572 [==============================] - 63s 2ms/step - loss: 1.8917\n",
      "\n",
      "Epoch 00037: loss improved from 1.91201 to 1.89169, saving model to RNN_weights.hdf5\n",
      "Epoch 38/500\n",
      "39572/39572 [==============================] - 62s 2ms/step - loss: 1.8696\n",
      "\n",
      "Epoch 00038: loss improved from 1.89169 to 1.86956, saving model to RNN_weights.hdf5\n",
      "Epoch 39/500\n",
      "39572/39572 [==============================] - 62s 2ms/step - loss: 1.8426\n",
      "\n",
      "Epoch 00039: loss improved from 1.86956 to 1.84263, saving model to RNN_weights.hdf5\n",
      "Epoch 40/500\n",
      "39572/39572 [==============================] - 62s 2ms/step - loss: 1.8091\n",
      "\n",
      "Epoch 00040: loss improved from 1.84263 to 1.80912, saving model to RNN_weights.hdf5\n",
      "Epoch 41/500\n",
      "39572/39572 [==============================] - 62s 2ms/step - loss: 1.7868\n",
      "\n",
      "Epoch 00041: loss improved from 1.80912 to 1.78680, saving model to RNN_weights.hdf5\n",
      "Epoch 42/500\n",
      "39572/39572 [==============================] - 63s 2ms/step - loss: 1.7696\n",
      "\n",
      "Epoch 00042: loss improved from 1.78680 to 1.76961, saving model to RNN_weights.hdf5\n",
      "Epoch 43/500\n",
      "39572/39572 [==============================] - 63s 2ms/step - loss: 1.7356\n",
      "\n",
      "Epoch 00043: loss improved from 1.76961 to 1.73559, saving model to RNN_weights.hdf5\n",
      "Epoch 44/500\n",
      "39572/39572 [==============================] - 63s 2ms/step - loss: 1.7188\n",
      "\n",
      "Epoch 00044: loss improved from 1.73559 to 1.71876, saving model to RNN_weights.hdf5\n",
      "Epoch 45/500\n",
      "39572/39572 [==============================] - 61s 2ms/step - loss: 1.6928\n",
      "\n",
      "Epoch 00045: loss improved from 1.71876 to 1.69277, saving model to RNN_weights.hdf5\n",
      "Epoch 46/500\n",
      "39572/39572 [==============================] - 72s 2ms/step - loss: 1.6731\n",
      "\n",
      "Epoch 00046: loss improved from 1.69277 to 1.67307, saving model to RNN_weights.hdf5\n",
      "Epoch 47/500\n",
      "39572/39572 [==============================] - 71s 2ms/step - loss: 1.6467\n",
      "\n",
      "Epoch 00047: loss improved from 1.67307 to 1.64675, saving model to RNN_weights.hdf5\n",
      "Epoch 48/500\n",
      "39572/39572 [==============================] - 66s 2ms/step - loss: 1.6284\n",
      "\n",
      "Epoch 00048: loss improved from 1.64675 to 1.62842, saving model to RNN_weights.hdf5\n",
      "Epoch 49/500\n",
      "39572/39572 [==============================] - 68s 2ms/step - loss: 1.6077\n",
      "\n",
      "Epoch 00049: loss improved from 1.62842 to 1.60766, saving model to RNN_weights.hdf5\n",
      "Epoch 50/500\n",
      "39572/39572 [==============================] - 65s 2ms/step - loss: 1.5933\n",
      "\n",
      "Epoch 00050: loss improved from 1.60766 to 1.59332, saving model to RNN_weights.hdf5\n",
      "Epoch 51/500\n",
      "39572/39572 [==============================] - 63s 2ms/step - loss: 1.5622\n",
      "\n",
      "Epoch 00051: loss improved from 1.59332 to 1.56224, saving model to RNN_weights.hdf5\n",
      "Epoch 52/500\n",
      "39572/39572 [==============================] - 67s 2ms/step - loss: 1.5428\n",
      "\n",
      "Epoch 00052: loss improved from 1.56224 to 1.54280, saving model to RNN_weights.hdf5\n",
      "Epoch 53/500\n",
      "39572/39572 [==============================] - 65s 2ms/step - loss: 1.5209\n",
      "\n",
      "Epoch 00053: loss improved from 1.54280 to 1.52088, saving model to RNN_weights.hdf5\n",
      "Epoch 54/500\n",
      "39572/39572 [==============================] - 66s 2ms/step - loss: 1.4980\n",
      "\n",
      "Epoch 00054: loss improved from 1.52088 to 1.49803, saving model to RNN_weights.hdf5\n",
      "Epoch 55/500\n",
      "39572/39572 [==============================] - 60s 2ms/step - loss: 1.4912\n",
      "\n",
      "Epoch 00055: loss improved from 1.49803 to 1.49115, saving model to RNN_weights.hdf5\n",
      "Epoch 56/500\n",
      "39572/39572 [==============================] - 59s 1ms/step - loss: 1.4552\n",
      "\n",
      "Epoch 00056: loss improved from 1.49115 to 1.45523, saving model to RNN_weights.hdf5\n",
      "Epoch 57/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 1.4417\n",
      "\n",
      "Epoch 00057: loss improved from 1.45523 to 1.44167, saving model to RNN_weights.hdf5\n",
      "Epoch 58/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.4154\n",
      "\n",
      "Epoch 00058: loss improved from 1.44167 to 1.41541, saving model to RNN_weights.hdf5\n",
      "Epoch 59/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.4115\n",
      "\n",
      "Epoch 00059: loss improved from 1.41541 to 1.41151, saving model to RNN_weights.hdf5\n",
      "Epoch 60/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.3862\n",
      "\n",
      "Epoch 00060: loss improved from 1.41151 to 1.38618, saving model to RNN_weights.hdf5\n",
      "Epoch 61/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.3733\n",
      "\n",
      "Epoch 00061: loss improved from 1.38618 to 1.37329, saving model to RNN_weights.hdf5\n",
      "Epoch 62/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.3598\n",
      "\n",
      "Epoch 00062: loss improved from 1.37329 to 1.35979, saving model to RNN_weights.hdf5\n",
      "Epoch 63/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.3409\n",
      "\n",
      "Epoch 00063: loss improved from 1.35979 to 1.34091, saving model to RNN_weights.hdf5\n",
      "Epoch 64/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.3180\n",
      "\n",
      "Epoch 00064: loss improved from 1.34091 to 1.31799, saving model to RNN_weights.hdf5\n",
      "Epoch 65/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.3038\n",
      "\n",
      "Epoch 00065: loss improved from 1.31799 to 1.30383, saving model to RNN_weights.hdf5\n",
      "Epoch 66/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.2866\n",
      "\n",
      "Epoch 00066: loss improved from 1.30383 to 1.28658, saving model to RNN_weights.hdf5\n",
      "Epoch 67/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.2700\n",
      "\n",
      "Epoch 00067: loss improved from 1.28658 to 1.27002, saving model to RNN_weights.hdf5\n",
      "Epoch 68/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.2614\n",
      "\n",
      "Epoch 00068: loss improved from 1.27002 to 1.26138, saving model to RNN_weights.hdf5\n",
      "Epoch 69/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.2412\n",
      "\n",
      "Epoch 00069: loss improved from 1.26138 to 1.24123, saving model to RNN_weights.hdf5\n",
      "Epoch 70/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.2339\n",
      "\n",
      "Epoch 00070: loss improved from 1.24123 to 1.23390, saving model to RNN_weights.hdf5\n",
      "Epoch 71/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.2070\n",
      "\n",
      "Epoch 00071: loss improved from 1.23390 to 1.20703, saving model to RNN_weights.hdf5\n",
      "Epoch 72/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1910\n",
      "\n",
      "Epoch 00072: loss improved from 1.20703 to 1.19098, saving model to RNN_weights.hdf5\n",
      "Epoch 73/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1832\n",
      "\n",
      "Epoch 00073: loss improved from 1.19098 to 1.18315, saving model to RNN_weights.hdf5\n",
      "Epoch 74/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1728\n",
      "\n",
      "Epoch 00074: loss improved from 1.18315 to 1.17280, saving model to RNN_weights.hdf5\n",
      "Epoch 75/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1512\n",
      "\n",
      "Epoch 00075: loss improved from 1.17280 to 1.15123, saving model to RNN_weights.hdf5\n",
      "Epoch 76/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1319\n",
      "\n",
      "Epoch 00076: loss improved from 1.15123 to 1.13193, saving model to RNN_weights.hdf5\n",
      "Epoch 77/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1322\n",
      "\n",
      "Epoch 00077: loss did not improve from 1.13193\n",
      "Epoch 78/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1219\n",
      "\n",
      "Epoch 00078: loss improved from 1.13193 to 1.12190, saving model to RNN_weights.hdf5\n",
      "Epoch 79/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.1047\n",
      "\n",
      "Epoch 00079: loss improved from 1.12190 to 1.10467, saving model to RNN_weights.hdf5\n",
      "Epoch 80/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0909\n",
      "\n",
      "Epoch 00080: loss improved from 1.10467 to 1.09094, saving model to RNN_weights.hdf5\n",
      "Epoch 81/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0802\n",
      "\n",
      "Epoch 00081: loss improved from 1.09094 to 1.08018, saving model to RNN_weights.hdf5\n",
      "Epoch 82/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0802\n",
      "\n",
      "Epoch 00082: loss did not improve from 1.08018\n",
      "Epoch 83/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0584\n",
      "\n",
      "Epoch 00083: loss improved from 1.08018 to 1.05837, saving model to RNN_weights.hdf5\n",
      "Epoch 84/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0436\n",
      "\n",
      "Epoch 00084: loss improved from 1.05837 to 1.04359, saving model to RNN_weights.hdf5\n",
      "Epoch 85/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0299\n",
      "\n",
      "Epoch 00085: loss improved from 1.04359 to 1.02992, saving model to RNN_weights.hdf5\n",
      "Epoch 86/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0207\n",
      "\n",
      "Epoch 00086: loss improved from 1.02992 to 1.02065, saving model to RNN_weights.hdf5\n",
      "Epoch 87/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0203\n",
      "\n",
      "Epoch 00087: loss improved from 1.02065 to 1.02035, saving model to RNN_weights.hdf5\n",
      "Epoch 88/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 1.0109\n",
      "\n",
      "Epoch 00088: loss improved from 1.02035 to 1.01089, saving model to RNN_weights.hdf5\n",
      "Epoch 89/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9909\n",
      "\n",
      "Epoch 00089: loss improved from 1.01089 to 0.99090, saving model to RNN_weights.hdf5\n",
      "Epoch 90/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9815\n",
      "\n",
      "Epoch 00090: loss improved from 0.99090 to 0.98150, saving model to RNN_weights.hdf5\n",
      "Epoch 91/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9690\n",
      "\n",
      "Epoch 00091: loss improved from 0.98150 to 0.96903, saving model to RNN_weights.hdf5\n",
      "Epoch 92/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9676\n",
      "\n",
      "Epoch 00092: loss improved from 0.96903 to 0.96756, saving model to RNN_weights.hdf5\n",
      "Epoch 93/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9470\n",
      "\n",
      "Epoch 00093: loss improved from 0.96756 to 0.94695, saving model to RNN_weights.hdf5\n",
      "Epoch 94/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9377\n",
      "\n",
      "Epoch 00094: loss improved from 0.94695 to 0.93772, saving model to RNN_weights.hdf5\n",
      "Epoch 95/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9323\n",
      "\n",
      "Epoch 00095: loss improved from 0.93772 to 0.93233, saving model to RNN_weights.hdf5\n",
      "Epoch 96/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.9244\n",
      "\n",
      "Epoch 00096: loss improved from 0.93233 to 0.92442, saving model to RNN_weights.hdf5\n",
      "Epoch 97/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9093\n",
      "\n",
      "Epoch 00097: loss improved from 0.92442 to 0.90928, saving model to RNN_weights.hdf5\n",
      "Epoch 98/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9032\n",
      "\n",
      "Epoch 00098: loss improved from 0.90928 to 0.90318, saving model to RNN_weights.hdf5\n",
      "Epoch 99/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.9053\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.90318\n",
      "Epoch 100/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.8915\n",
      "\n",
      "Epoch 00100: loss improved from 0.90318 to 0.89155, saving model to RNN_weights.hdf5\n",
      "Epoch 101/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.8794\n",
      "\n",
      "Epoch 00101: loss improved from 0.89155 to 0.87941, saving model to RNN_weights.hdf5\n",
      "Epoch 102/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.8717\n",
      "\n",
      "Epoch 00102: loss improved from 0.87941 to 0.87167, saving model to RNN_weights.hdf5\n",
      "Epoch 103/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 0.8653\n",
      "\n",
      "Epoch 00103: loss improved from 0.87167 to 0.86530, saving model to RNN_weights.hdf5\n",
      "Epoch 104/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.8470\n",
      "\n",
      "Epoch 00104: loss improved from 0.86530 to 0.84704, saving model to RNN_weights.hdf5\n",
      "Epoch 105/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.8408\n",
      "\n",
      "Epoch 00105: loss improved from 0.84704 to 0.84081, saving model to RNN_weights.hdf5\n",
      "Epoch 106/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 0.8308\n",
      "\n",
      "Epoch 00106: loss improved from 0.84081 to 0.83085, saving model to RNN_weights.hdf5\n",
      "Epoch 107/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.8381\n",
      "\n",
      "Epoch 00107: loss did not improve from 0.83085\n",
      "Epoch 108/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.8159\n",
      "\n",
      "Epoch 00108: loss improved from 0.83085 to 0.81591, saving model to RNN_weights.hdf5\n",
      "Epoch 109/500\n",
      "39572/39572 [==============================] - 59s 1ms/step - loss: 0.7982\n",
      "\n",
      "Epoch 00109: loss improved from 0.81591 to 0.79815, saving model to RNN_weights.hdf5\n",
      "Epoch 110/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.8160\n",
      "\n",
      "Epoch 00110: loss did not improve from 0.79815\n",
      "Epoch 111/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.8080\n",
      "\n",
      "Epoch 00111: loss did not improve from 0.79815\n",
      "Epoch 112/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.8045\n",
      "\n",
      "Epoch 00112: loss did not improve from 0.79815\n",
      "Epoch 113/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.7893\n",
      "\n",
      "Epoch 00113: loss improved from 0.79815 to 0.78931, saving model to RNN_weights.hdf5\n",
      "Epoch 114/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 0.7751\n",
      "\n",
      "Epoch 00114: loss improved from 0.78931 to 0.77511, saving model to RNN_weights.hdf5\n",
      "Epoch 115/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7760\n",
      "\n",
      "Epoch 00115: loss did not improve from 0.77511\n",
      "Epoch 116/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7590\n",
      "\n",
      "Epoch 00116: loss improved from 0.77511 to 0.75903, saving model to RNN_weights.hdf5\n",
      "Epoch 117/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7656\n",
      "\n",
      "Epoch 00117: loss did not improve from 0.75903\n",
      "Epoch 118/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7590\n",
      "\n",
      "Epoch 00118: loss did not improve from 0.75903\n",
      "Epoch 119/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7427\n",
      "\n",
      "Epoch 00119: loss improved from 0.75903 to 0.74274, saving model to RNN_weights.hdf5\n",
      "Epoch 120/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7345\n",
      "\n",
      "Epoch 00120: loss improved from 0.74274 to 0.73451, saving model to RNN_weights.hdf5\n",
      "Epoch 121/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7426\n",
      "\n",
      "Epoch 00121: loss did not improve from 0.73451\n",
      "Epoch 122/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7258\n",
      "\n",
      "Epoch 00122: loss improved from 0.73451 to 0.72577, saving model to RNN_weights.hdf5\n",
      "Epoch 123/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7295\n",
      "\n",
      "Epoch 00123: loss did not improve from 0.72577\n",
      "Epoch 124/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7198\n",
      "\n",
      "Epoch 00124: loss improved from 0.72577 to 0.71978, saving model to RNN_weights.hdf5\n",
      "Epoch 125/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7090\n",
      "\n",
      "Epoch 00125: loss improved from 0.71978 to 0.70900, saving model to RNN_weights.hdf5\n",
      "Epoch 126/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.7179\n",
      "\n",
      "Epoch 00126: loss did not improve from 0.70900\n",
      "Epoch 127/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.7069\n",
      "\n",
      "Epoch 00127: loss improved from 0.70900 to 0.70690, saving model to RNN_weights.hdf5\n",
      "Epoch 128/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6894\n",
      "\n",
      "Epoch 00128: loss improved from 0.70690 to 0.68936, saving model to RNN_weights.hdf5\n",
      "Epoch 129/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6971\n",
      "\n",
      "Epoch 00129: loss did not improve from 0.68936\n",
      "Epoch 130/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6842\n",
      "\n",
      "Epoch 00130: loss improved from 0.68936 to 0.68421, saving model to RNN_weights.hdf5\n",
      "Epoch 131/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6936\n",
      "\n",
      "Epoch 00131: loss did not improve from 0.68421\n",
      "Epoch 132/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6832\n",
      "\n",
      "Epoch 00132: loss improved from 0.68421 to 0.68317, saving model to RNN_weights.hdf5\n",
      "Epoch 133/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6723\n",
      "\n",
      "Epoch 00133: loss improved from 0.68317 to 0.67235, saving model to RNN_weights.hdf5\n",
      "Epoch 134/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6673\n",
      "\n",
      "Epoch 00134: loss improved from 0.67235 to 0.66726, saving model to RNN_weights.hdf5\n",
      "Epoch 135/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6591\n",
      "\n",
      "Epoch 00135: loss improved from 0.66726 to 0.65912, saving model to RNN_weights.hdf5\n",
      "Epoch 136/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6766\n",
      "\n",
      "Epoch 00136: loss did not improve from 0.65912\n",
      "Epoch 137/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6525\n",
      "\n",
      "Epoch 00137: loss improved from 0.65912 to 0.65252, saving model to RNN_weights.hdf5\n",
      "Epoch 138/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6391\n",
      "\n",
      "Epoch 00138: loss improved from 0.65252 to 0.63912, saving model to RNN_weights.hdf5\n",
      "Epoch 139/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6402\n",
      "\n",
      "Epoch 00139: loss did not improve from 0.63912\n",
      "Epoch 140/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6533\n",
      "\n",
      "Epoch 00140: loss did not improve from 0.63912\n",
      "Epoch 141/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6302\n",
      "\n",
      "Epoch 00141: loss improved from 0.63912 to 0.63024, saving model to RNN_weights.hdf5\n",
      "Epoch 142/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6145\n",
      "\n",
      "Epoch 00142: loss improved from 0.63024 to 0.61447, saving model to RNN_weights.hdf5\n",
      "Epoch 143/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6248\n",
      "\n",
      "Epoch 00143: loss did not improve from 0.61447\n",
      "Epoch 144/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6233\n",
      "\n",
      "Epoch 00144: loss did not improve from 0.61447\n",
      "Epoch 145/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6080\n",
      "\n",
      "Epoch 00145: loss improved from 0.61447 to 0.60798, saving model to RNN_weights.hdf5\n",
      "Epoch 146/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6150\n",
      "\n",
      "Epoch 00146: loss did not improve from 0.60798\n",
      "Epoch 147/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6080\n",
      "\n",
      "Epoch 00147: loss improved from 0.60798 to 0.60796, saving model to RNN_weights.hdf5\n",
      "Epoch 148/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6055\n",
      "\n",
      "Epoch 00148: loss improved from 0.60796 to 0.60548, saving model to RNN_weights.hdf5\n",
      "Epoch 149/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6093\n",
      "\n",
      "Epoch 00149: loss did not improve from 0.60548\n",
      "Epoch 150/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.6072\n",
      "\n",
      "Epoch 00150: loss did not improve from 0.60548\n",
      "Epoch 151/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5878\n",
      "\n",
      "Epoch 00151: loss improved from 0.60548 to 0.58785, saving model to RNN_weights.hdf5\n",
      "Epoch 152/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5854\n",
      "\n",
      "Epoch 00152: loss improved from 0.58785 to 0.58535, saving model to RNN_weights.hdf5\n",
      "Epoch 153/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5744\n",
      "\n",
      "Epoch 00153: loss improved from 0.58535 to 0.57443, saving model to RNN_weights.hdf5\n",
      "Epoch 154/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5947\n",
      "\n",
      "Epoch 00154: loss did not improve from 0.57443\n",
      "Epoch 155/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5825\n",
      "\n",
      "Epoch 00155: loss did not improve from 0.57443\n",
      "Epoch 156/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5685\n",
      "\n",
      "Epoch 00156: loss improved from 0.57443 to 0.56852, saving model to RNN_weights.hdf5\n",
      "Epoch 157/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5708\n",
      "\n",
      "Epoch 00157: loss did not improve from 0.56852\n",
      "Epoch 158/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5725\n",
      "\n",
      "Epoch 00158: loss did not improve from 0.56852\n",
      "Epoch 159/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5748\n",
      "\n",
      "Epoch 00159: loss did not improve from 0.56852\n",
      "Epoch 160/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5657\n",
      "\n",
      "Epoch 00160: loss improved from 0.56852 to 0.56568, saving model to RNN_weights.hdf5\n",
      "Epoch 161/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5812\n",
      "\n",
      "Epoch 00161: loss did not improve from 0.56568\n",
      "Epoch 162/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5541\n",
      "\n",
      "Epoch 00162: loss improved from 0.56568 to 0.55413, saving model to RNN_weights.hdf5\n",
      "Epoch 163/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5474\n",
      "\n",
      "Epoch 00163: loss improved from 0.55413 to 0.54740, saving model to RNN_weights.hdf5\n",
      "Epoch 164/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5609\n",
      "\n",
      "Epoch 00164: loss did not improve from 0.54740\n",
      "Epoch 165/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5388\n",
      "\n",
      "Epoch 00165: loss improved from 0.54740 to 0.53875, saving model to RNN_weights.hdf5\n",
      "Epoch 166/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5370\n",
      "\n",
      "Epoch 00166: loss improved from 0.53875 to 0.53702, saving model to RNN_weights.hdf5\n",
      "Epoch 167/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5325\n",
      "\n",
      "Epoch 00167: loss improved from 0.53702 to 0.53254, saving model to RNN_weights.hdf5\n",
      "Epoch 168/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5336\n",
      "\n",
      "Epoch 00168: loss did not improve from 0.53254\n",
      "Epoch 169/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5318\n",
      "\n",
      "Epoch 00169: loss improved from 0.53254 to 0.53176, saving model to RNN_weights.hdf5\n",
      "Epoch 170/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5370\n",
      "\n",
      "Epoch 00170: loss did not improve from 0.53176\n",
      "Epoch 171/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5210\n",
      "\n",
      "Epoch 00171: loss improved from 0.53176 to 0.52097, saving model to RNN_weights.hdf5\n",
      "Epoch 172/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5299\n",
      "\n",
      "Epoch 00172: loss did not improve from 0.52097\n",
      "Epoch 173/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.5188\n",
      "\n",
      "Epoch 00173: loss improved from 0.52097 to 0.51881, saving model to RNN_weights.hdf5\n",
      "Epoch 174/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5192\n",
      "\n",
      "Epoch 00174: loss did not improve from 0.51881\n",
      "Epoch 175/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5109\n",
      "\n",
      "Epoch 00175: loss improved from 0.51881 to 0.51087, saving model to RNN_weights.hdf5\n",
      "Epoch 176/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5180\n",
      "\n",
      "Epoch 00176: loss did not improve from 0.51087\n",
      "Epoch 177/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5128\n",
      "\n",
      "Epoch 00177: loss did not improve from 0.51087\n",
      "Epoch 178/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5047\n",
      "\n",
      "Epoch 00178: loss improved from 0.51087 to 0.50473, saving model to RNN_weights.hdf5\n",
      "Epoch 179/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5110\n",
      "\n",
      "Epoch 00179: loss did not improve from 0.50473\n",
      "Epoch 180/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4988\n",
      "\n",
      "Epoch 00180: loss improved from 0.50473 to 0.49879, saving model to RNN_weights.hdf5\n",
      "Epoch 181/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5000\n",
      "\n",
      "Epoch 00181: loss did not improve from 0.49879\n",
      "Epoch 182/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4922\n",
      "\n",
      "Epoch 00182: loss improved from 0.49879 to 0.49216, saving model to RNN_weights.hdf5\n",
      "Epoch 183/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5001\n",
      "\n",
      "Epoch 00183: loss did not improve from 0.49216\n",
      "Epoch 184/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.5065\n",
      "\n",
      "Epoch 00184: loss did not improve from 0.49216\n",
      "Epoch 185/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4923\n",
      "\n",
      "Epoch 00185: loss did not improve from 0.49216\n",
      "Epoch 186/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4876\n",
      "\n",
      "Epoch 00186: loss improved from 0.49216 to 0.48763, saving model to RNN_weights.hdf5\n",
      "Epoch 187/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4940\n",
      "\n",
      "Epoch 00187: loss did not improve from 0.48763\n",
      "Epoch 188/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4876\n",
      "\n",
      "Epoch 00188: loss improved from 0.48763 to 0.48762, saving model to RNN_weights.hdf5\n",
      "Epoch 189/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4772\n",
      "\n",
      "Epoch 00189: loss improved from 0.48762 to 0.47716, saving model to RNN_weights.hdf5\n",
      "Epoch 190/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4602\n",
      "\n",
      "Epoch 00190: loss improved from 0.47716 to 0.46018, saving model to RNN_weights.hdf5\n",
      "Epoch 191/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4753\n",
      "\n",
      "Epoch 00191: loss did not improve from 0.46018\n",
      "Epoch 192/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4735\n",
      "\n",
      "Epoch 00192: loss did not improve from 0.46018\n",
      "Epoch 193/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4749\n",
      "\n",
      "Epoch 00193: loss did not improve from 0.46018\n",
      "Epoch 194/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4718\n",
      "\n",
      "Epoch 00194: loss did not improve from 0.46018\n",
      "Epoch 195/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4681\n",
      "\n",
      "Epoch 00195: loss did not improve from 0.46018\n",
      "Epoch 196/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4548\n",
      "\n",
      "Epoch 00196: loss improved from 0.46018 to 0.45484, saving model to RNN_weights.hdf5\n",
      "Epoch 197/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4629\n",
      "\n",
      "Epoch 00197: loss did not improve from 0.45484\n",
      "Epoch 198/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4695\n",
      "\n",
      "Epoch 00198: loss did not improve from 0.45484\n",
      "Epoch 199/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4559\n",
      "\n",
      "Epoch 00199: loss did not improve from 0.45484\n",
      "Epoch 200/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4529\n",
      "\n",
      "Epoch 00200: loss improved from 0.45484 to 0.45295, saving model to RNN_weights.hdf5\n",
      "Epoch 201/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4460\n",
      "\n",
      "Epoch 00201: loss improved from 0.45295 to 0.44603, saving model to RNN_weights.hdf5\n",
      "Epoch 202/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4391\n",
      "\n",
      "Epoch 00202: loss improved from 0.44603 to 0.43915, saving model to RNN_weights.hdf5\n",
      "Epoch 203/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4471\n",
      "\n",
      "Epoch 00203: loss did not improve from 0.43915\n",
      "Epoch 204/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4552\n",
      "\n",
      "Epoch 00204: loss did not improve from 0.43915\n",
      "Epoch 205/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4504\n",
      "\n",
      "Epoch 00205: loss did not improve from 0.43915\n",
      "Epoch 206/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4683\n",
      "\n",
      "Epoch 00206: loss did not improve from 0.43915\n",
      "Epoch 207/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4359\n",
      "\n",
      "Epoch 00207: loss improved from 0.43915 to 0.43591, saving model to RNN_weights.hdf5\n",
      "Epoch 208/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4450\n",
      "\n",
      "Epoch 00208: loss did not improve from 0.43591\n",
      "Epoch 209/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4281\n",
      "\n",
      "Epoch 00209: loss improved from 0.43591 to 0.42812, saving model to RNN_weights.hdf5\n",
      "Epoch 210/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4386\n",
      "\n",
      "Epoch 00210: loss did not improve from 0.42812\n",
      "Epoch 211/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4303\n",
      "\n",
      "Epoch 00211: loss did not improve from 0.42812\n",
      "Epoch 212/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4257\n",
      "\n",
      "Epoch 00212: loss improved from 0.42812 to 0.42569, saving model to RNN_weights.hdf5\n",
      "Epoch 213/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4264\n",
      "\n",
      "Epoch 00213: loss did not improve from 0.42569\n",
      "Epoch 214/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4243\n",
      "\n",
      "Epoch 00214: loss improved from 0.42569 to 0.42433, saving model to RNN_weights.hdf5\n",
      "Epoch 215/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4226\n",
      "\n",
      "Epoch 00215: loss improved from 0.42433 to 0.42256, saving model to RNN_weights.hdf5\n",
      "Epoch 216/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4198\n",
      "\n",
      "Epoch 00216: loss improved from 0.42256 to 0.41976, saving model to RNN_weights.hdf5\n",
      "Epoch 217/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4146\n",
      "\n",
      "Epoch 00217: loss improved from 0.41976 to 0.41461, saving model to RNN_weights.hdf5\n",
      "Epoch 218/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4253\n",
      "\n",
      "Epoch 00218: loss did not improve from 0.41461\n",
      "Epoch 219/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4346\n",
      "\n",
      "Epoch 00219: loss did not improve from 0.41461\n",
      "Epoch 220/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4271\n",
      "\n",
      "Epoch 00220: loss did not improve from 0.41461\n",
      "Epoch 221/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4217\n",
      "\n",
      "Epoch 00221: loss did not improve from 0.41461\n",
      "Epoch 222/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4028\n",
      "\n",
      "Epoch 00222: loss improved from 0.41461 to 0.40282, saving model to RNN_weights.hdf5\n",
      "Epoch 223/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4123\n",
      "\n",
      "Epoch 00223: loss did not improve from 0.40282\n",
      "Epoch 224/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4193\n",
      "\n",
      "Epoch 00224: loss did not improve from 0.40282\n",
      "Epoch 225/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3929\n",
      "\n",
      "Epoch 00225: loss improved from 0.40282 to 0.39291, saving model to RNN_weights.hdf5\n",
      "Epoch 226/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4045\n",
      "\n",
      "Epoch 00226: loss did not improve from 0.39291\n",
      "Epoch 227/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4010\n",
      "\n",
      "Epoch 00227: loss did not improve from 0.39291\n",
      "Epoch 228/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3974\n",
      "\n",
      "Epoch 00228: loss did not improve from 0.39291\n",
      "Epoch 229/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4058\n",
      "\n",
      "Epoch 00229: loss did not improve from 0.39291\n",
      "Epoch 230/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4084\n",
      "\n",
      "Epoch 00230: loss did not improve from 0.39291\n",
      "Epoch 231/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4065\n",
      "\n",
      "Epoch 00231: loss did not improve from 0.39291\n",
      "Epoch 232/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3919\n",
      "\n",
      "Epoch 00232: loss improved from 0.39291 to 0.39191, saving model to RNN_weights.hdf5\n",
      "Epoch 233/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.3961\n",
      "\n",
      "Epoch 00233: loss did not improve from 0.39191\n",
      "Epoch 234/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4032\n",
      "\n",
      "Epoch 00234: loss did not improve from 0.39191\n",
      "Epoch 235/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3871\n",
      "\n",
      "Epoch 00235: loss improved from 0.39191 to 0.38715, saving model to RNN_weights.hdf5\n",
      "Epoch 236/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.4039\n",
      "\n",
      "Epoch 00236: loss did not improve from 0.38715\n",
      "Epoch 237/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.3992\n",
      "\n",
      "Epoch 00237: loss did not improve from 0.38715\n",
      "Epoch 238/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3949\n",
      "\n",
      "Epoch 00238: loss did not improve from 0.38715\n",
      "Epoch 239/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3783\n",
      "\n",
      "Epoch 00239: loss improved from 0.38715 to 0.37828, saving model to RNN_weights.hdf5\n",
      "Epoch 240/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3835\n",
      "\n",
      "Epoch 00240: loss did not improve from 0.37828\n",
      "Epoch 241/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3858\n",
      "\n",
      "Epoch 00241: loss did not improve from 0.37828\n",
      "Epoch 242/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3834\n",
      "\n",
      "Epoch 00242: loss did not improve from 0.37828\n",
      "Epoch 243/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 0.3834\n",
      "\n",
      "Epoch 00243: loss did not improve from 0.37828\n",
      "Epoch 244/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3789\n",
      "\n",
      "Epoch 00244: loss did not improve from 0.37828\n",
      "Epoch 245/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3799\n",
      "\n",
      "Epoch 00245: loss did not improve from 0.37828\n",
      "Epoch 246/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3748\n",
      "\n",
      "Epoch 00246: loss improved from 0.37828 to 0.37477, saving model to RNN_weights.hdf5\n",
      "Epoch 247/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3742\n",
      "\n",
      "Epoch 00247: loss improved from 0.37477 to 0.37424, saving model to RNN_weights.hdf5\n",
      "Epoch 248/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.3833\n",
      "\n",
      "Epoch 00248: loss did not improve from 0.37424\n",
      "Epoch 249/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3690\n",
      "\n",
      "Epoch 00249: loss improved from 0.37424 to 0.36897, saving model to RNN_weights.hdf5\n",
      "Epoch 250/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3776\n",
      "\n",
      "Epoch 00250: loss did not improve from 0.36897\n",
      "Epoch 251/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3687\n",
      "\n",
      "Epoch 00251: loss improved from 0.36897 to 0.36874, saving model to RNN_weights.hdf5\n",
      "Epoch 252/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3684\n",
      "\n",
      "Epoch 00252: loss improved from 0.36874 to 0.36840, saving model to RNN_weights.hdf5\n",
      "Epoch 253/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3636\n",
      "\n",
      "Epoch 00253: loss improved from 0.36840 to 0.36362, saving model to RNN_weights.hdf5\n",
      "Epoch 254/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3681\n",
      "\n",
      "Epoch 00254: loss did not improve from 0.36362\n",
      "Epoch 255/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3616\n",
      "\n",
      "Epoch 00255: loss improved from 0.36362 to 0.36158, saving model to RNN_weights.hdf5\n",
      "Epoch 256/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3625\n",
      "\n",
      "Epoch 00256: loss did not improve from 0.36158\n",
      "Epoch 257/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3580\n",
      "\n",
      "Epoch 00257: loss improved from 0.36158 to 0.35802, saving model to RNN_weights.hdf5\n",
      "Epoch 258/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3667\n",
      "\n",
      "Epoch 00258: loss did not improve from 0.35802\n",
      "Epoch 259/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.3665\n",
      "\n",
      "Epoch 00259: loss did not improve from 0.35802\n",
      "Epoch 260/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3647\n",
      "\n",
      "Epoch 00260: loss did not improve from 0.35802\n",
      "Epoch 261/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3577\n",
      "\n",
      "Epoch 00261: loss improved from 0.35802 to 0.35773, saving model to RNN_weights.hdf5\n",
      "Epoch 262/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3562\n",
      "\n",
      "Epoch 00262: loss improved from 0.35773 to 0.35618, saving model to RNN_weights.hdf5\n",
      "Epoch 263/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3521\n",
      "\n",
      "Epoch 00263: loss improved from 0.35618 to 0.35214, saving model to RNN_weights.hdf5\n",
      "Epoch 264/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3656\n",
      "\n",
      "Epoch 00264: loss did not improve from 0.35214\n",
      "Epoch 265/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3465\n",
      "\n",
      "Epoch 00265: loss improved from 0.35214 to 0.34648, saving model to RNN_weights.hdf5\n",
      "Epoch 266/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3580\n",
      "\n",
      "Epoch 00266: loss did not improve from 0.34648\n",
      "Epoch 267/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3602\n",
      "\n",
      "Epoch 00267: loss did not improve from 0.34648\n",
      "Epoch 268/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3483\n",
      "\n",
      "Epoch 00268: loss did not improve from 0.34648\n",
      "Epoch 269/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3450\n",
      "\n",
      "Epoch 00269: loss improved from 0.34648 to 0.34495, saving model to RNN_weights.hdf5\n",
      "Epoch 270/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3498\n",
      "\n",
      "Epoch 00270: loss did not improve from 0.34495\n",
      "Epoch 271/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3544\n",
      "\n",
      "Epoch 00271: loss did not improve from 0.34495\n",
      "Epoch 272/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3588\n",
      "\n",
      "Epoch 00272: loss did not improve from 0.34495\n",
      "Epoch 273/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3444\n",
      "\n",
      "Epoch 00273: loss improved from 0.34495 to 0.34436, saving model to RNN_weights.hdf5\n",
      "Epoch 274/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3399\n",
      "\n",
      "Epoch 00274: loss improved from 0.34436 to 0.33988, saving model to RNN_weights.hdf5\n",
      "Epoch 275/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3519\n",
      "\n",
      "Epoch 00275: loss did not improve from 0.33988\n",
      "Epoch 276/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3443\n",
      "\n",
      "Epoch 00276: loss did not improve from 0.33988\n",
      "Epoch 277/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3559\n",
      "\n",
      "Epoch 00277: loss did not improve from 0.33988\n",
      "Epoch 278/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3455\n",
      "\n",
      "Epoch 00278: loss did not improve from 0.33988\n",
      "Epoch 279/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3429\n",
      "\n",
      "Epoch 00279: loss did not improve from 0.33988\n",
      "Epoch 280/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3436\n",
      "\n",
      "Epoch 00280: loss did not improve from 0.33988\n",
      "Epoch 281/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3348\n",
      "\n",
      "Epoch 00281: loss improved from 0.33988 to 0.33484, saving model to RNN_weights.hdf5\n",
      "Epoch 282/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3368\n",
      "\n",
      "Epoch 00282: loss did not improve from 0.33484\n",
      "Epoch 283/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3358\n",
      "\n",
      "Epoch 00283: loss did not improve from 0.33484\n",
      "Epoch 284/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3393\n",
      "\n",
      "Epoch 00284: loss did not improve from 0.33484\n",
      "Epoch 285/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3445\n",
      "\n",
      "Epoch 00285: loss did not improve from 0.33484\n",
      "Epoch 286/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3425\n",
      "\n",
      "Epoch 00286: loss did not improve from 0.33484\n",
      "Epoch 287/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3415\n",
      "\n",
      "Epoch 00287: loss did not improve from 0.33484\n",
      "Epoch 288/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3294\n",
      "\n",
      "Epoch 00288: loss improved from 0.33484 to 0.32944, saving model to RNN_weights.hdf5\n",
      "Epoch 289/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3299\n",
      "\n",
      "Epoch 00289: loss did not improve from 0.32944\n",
      "Epoch 290/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3381\n",
      "\n",
      "Epoch 00290: loss did not improve from 0.32944\n",
      "Epoch 291/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3300\n",
      "\n",
      "Epoch 00291: loss did not improve from 0.32944\n",
      "Epoch 292/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3279\n",
      "\n",
      "Epoch 00292: loss improved from 0.32944 to 0.32787, saving model to RNN_weights.hdf5\n",
      "Epoch 293/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3218\n",
      "\n",
      "Epoch 00293: loss improved from 0.32787 to 0.32184, saving model to RNN_weights.hdf5\n",
      "Epoch 294/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3170\n",
      "\n",
      "Epoch 00294: loss improved from 0.32184 to 0.31698, saving model to RNN_weights.hdf5\n",
      "Epoch 295/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3239\n",
      "\n",
      "Epoch 00295: loss did not improve from 0.31698\n",
      "Epoch 296/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3254\n",
      "\n",
      "Epoch 00296: loss did not improve from 0.31698\n",
      "Epoch 297/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3137\n",
      "\n",
      "Epoch 00297: loss improved from 0.31698 to 0.31371, saving model to RNN_weights.hdf5\n",
      "Epoch 298/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3176\n",
      "\n",
      "Epoch 00298: loss did not improve from 0.31371\n",
      "Epoch 299/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3216\n",
      "\n",
      "Epoch 00299: loss did not improve from 0.31371\n",
      "Epoch 300/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3253\n",
      "\n",
      "Epoch 00300: loss did not improve from 0.31371\n",
      "Epoch 301/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 0.3215\n",
      "\n",
      "Epoch 00301: loss did not improve from 0.31371\n",
      "Epoch 302/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3157\n",
      "\n",
      "Epoch 00302: loss did not improve from 0.31371\n",
      "Epoch 303/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3155\n",
      "\n",
      "Epoch 00303: loss did not improve from 0.31371\n",
      "Epoch 304/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3096\n",
      "\n",
      "Epoch 00304: loss improved from 0.31371 to 0.30961, saving model to RNN_weights.hdf5\n",
      "Epoch 305/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3205\n",
      "\n",
      "Epoch 00305: loss did not improve from 0.30961\n",
      "Epoch 306/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3033\n",
      "\n",
      "Epoch 00306: loss improved from 0.30961 to 0.30332, saving model to RNN_weights.hdf5\n",
      "Epoch 307/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.3191\n",
      "\n",
      "Epoch 00307: loss did not improve from 0.30332\n",
      "Epoch 308/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3157\n",
      "\n",
      "Epoch 00308: loss did not improve from 0.30332\n",
      "Epoch 309/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3117\n",
      "\n",
      "Epoch 00309: loss did not improve from 0.30332\n",
      "Epoch 310/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3121\n",
      "\n",
      "Epoch 00310: loss did not improve from 0.30332\n",
      "Epoch 311/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3154\n",
      "\n",
      "Epoch 00311: loss did not improve from 0.30332\n",
      "Epoch 312/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3165\n",
      "\n",
      "Epoch 00312: loss did not improve from 0.30332\n",
      "Epoch 313/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3046\n",
      "\n",
      "Epoch 00313: loss did not improve from 0.30332\n",
      "Epoch 314/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2939\n",
      "\n",
      "Epoch 00314: loss improved from 0.30332 to 0.29386, saving model to RNN_weights.hdf5\n",
      "Epoch 315/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3096\n",
      "\n",
      "Epoch 00315: loss did not improve from 0.29386\n",
      "Epoch 316/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3150\n",
      "\n",
      "Epoch 00316: loss did not improve from 0.29386\n",
      "Epoch 317/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3131\n",
      "\n",
      "Epoch 00317: loss did not improve from 0.29386\n",
      "Epoch 318/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3105\n",
      "\n",
      "Epoch 00318: loss did not improve from 0.29386\n",
      "Epoch 319/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3011\n",
      "\n",
      "Epoch 00319: loss did not improve from 0.29386\n",
      "Epoch 320/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3022\n",
      "\n",
      "Epoch 00320: loss did not improve from 0.29386\n",
      "Epoch 321/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3079\n",
      "\n",
      "Epoch 00321: loss did not improve from 0.29386\n",
      "Epoch 322/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3083\n",
      "\n",
      "Epoch 00322: loss did not improve from 0.29386\n",
      "Epoch 323/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3043\n",
      "\n",
      "Epoch 00323: loss did not improve from 0.29386\n",
      "Epoch 324/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3127\n",
      "\n",
      "Epoch 00324: loss did not improve from 0.29386\n",
      "Epoch 325/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3123\n",
      "\n",
      "Epoch 00325: loss did not improve from 0.29386\n",
      "Epoch 326/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3068\n",
      "\n",
      "Epoch 00326: loss did not improve from 0.29386\n",
      "Epoch 327/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3033\n",
      "\n",
      "Epoch 00327: loss did not improve from 0.29386\n",
      "Epoch 328/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2981\n",
      "\n",
      "Epoch 00328: loss did not improve from 0.29386\n",
      "Epoch 329/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3059\n",
      "\n",
      "Epoch 00329: loss did not improve from 0.29386\n",
      "Epoch 330/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2979\n",
      "\n",
      "Epoch 00330: loss did not improve from 0.29386\n",
      "Epoch 331/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3015\n",
      "\n",
      "Epoch 00331: loss did not improve from 0.29386\n",
      "Epoch 332/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2931\n",
      "\n",
      "Epoch 00332: loss improved from 0.29386 to 0.29308, saving model to RNN_weights.hdf5\n",
      "Epoch 333/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2866\n",
      "\n",
      "Epoch 00333: loss improved from 0.29308 to 0.28657, saving model to RNN_weights.hdf5\n",
      "Epoch 334/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3011\n",
      "\n",
      "Epoch 00334: loss did not improve from 0.28657\n",
      "Epoch 335/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2888\n",
      "\n",
      "Epoch 00335: loss did not improve from 0.28657\n",
      "Epoch 336/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2970\n",
      "\n",
      "Epoch 00336: loss did not improve from 0.28657\n",
      "Epoch 337/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2898\n",
      "\n",
      "Epoch 00337: loss did not improve from 0.28657\n",
      "Epoch 338/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3025\n",
      "\n",
      "Epoch 00338: loss did not improve from 0.28657\n",
      "Epoch 339/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.3092\n",
      "\n",
      "Epoch 00339: loss did not improve from 0.28657\n",
      "Epoch 340/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2891\n",
      "\n",
      "Epoch 00340: loss did not improve from 0.28657\n",
      "Epoch 341/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2943\n",
      "\n",
      "Epoch 00341: loss did not improve from 0.28657\n",
      "Epoch 342/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2979\n",
      "\n",
      "Epoch 00342: loss did not improve from 0.28657\n",
      "Epoch 343/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2917\n",
      "\n",
      "Epoch 00343: loss did not improve from 0.28657\n",
      "Epoch 344/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2950\n",
      "\n",
      "Epoch 00344: loss did not improve from 0.28657\n",
      "Epoch 345/500\n",
      "39572/39572 [==============================] - 59s 1ms/step - loss: 0.2892\n",
      "\n",
      "Epoch 00345: loss did not improve from 0.28657\n",
      "Epoch 346/500\n",
      "39572/39572 [==============================] - 61s 2ms/step - loss: 0.2884\n",
      "\n",
      "Epoch 00346: loss did not improve from 0.28657\n",
      "Epoch 347/500\n",
      "39572/39572 [==============================] - 61s 2ms/step - loss: 0.2988\n",
      "\n",
      "Epoch 00347: loss did not improve from 0.28657\n",
      "Epoch 348/500\n",
      "39572/39572 [==============================] - 59s 2ms/step - loss: 0.2833\n",
      "\n",
      "Epoch 00348: loss improved from 0.28657 to 0.28325, saving model to RNN_weights.hdf5\n",
      "Epoch 349/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2925\n",
      "\n",
      "Epoch 00349: loss did not improve from 0.28325\n",
      "Epoch 350/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2875\n",
      "\n",
      "Epoch 00350: loss did not improve from 0.28325\n",
      "Epoch 351/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2738\n",
      "\n",
      "Epoch 00351: loss improved from 0.28325 to 0.27382, saving model to RNN_weights.hdf5\n",
      "Epoch 352/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2757\n",
      "\n",
      "Epoch 00352: loss did not improve from 0.27382\n",
      "Epoch 353/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2963\n",
      "\n",
      "Epoch 00353: loss did not improve from 0.27382\n",
      "Epoch 354/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2856\n",
      "\n",
      "Epoch 00354: loss did not improve from 0.27382\n",
      "Epoch 355/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2779\n",
      "\n",
      "Epoch 00355: loss did not improve from 0.27382\n",
      "Epoch 356/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2824\n",
      "\n",
      "Epoch 00356: loss did not improve from 0.27382\n",
      "Epoch 357/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2803\n",
      "\n",
      "Epoch 00357: loss did not improve from 0.27382\n",
      "Epoch 358/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2756\n",
      "\n",
      "Epoch 00358: loss did not improve from 0.27382\n",
      "Epoch 359/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2833\n",
      "\n",
      "Epoch 00359: loss did not improve from 0.27382\n",
      "Epoch 360/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2826\n",
      "\n",
      "Epoch 00360: loss did not improve from 0.27382\n",
      "Epoch 361/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2693\n",
      "\n",
      "Epoch 00361: loss improved from 0.27382 to 0.26925, saving model to RNN_weights.hdf5\n",
      "Epoch 362/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2865\n",
      "\n",
      "Epoch 00362: loss did not improve from 0.26925\n",
      "Epoch 363/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2781\n",
      "\n",
      "Epoch 00363: loss did not improve from 0.26925\n",
      "Epoch 364/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2733\n",
      "\n",
      "Epoch 00364: loss did not improve from 0.26925\n",
      "Epoch 365/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.2708\n",
      "\n",
      "Epoch 00365: loss did not improve from 0.26925\n",
      "Epoch 366/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2701\n",
      "\n",
      "Epoch 00366: loss did not improve from 0.26925\n",
      "Epoch 367/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2723\n",
      "\n",
      "Epoch 00367: loss did not improve from 0.26925\n",
      "Epoch 368/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2698\n",
      "\n",
      "Epoch 00368: loss did not improve from 0.26925\n",
      "Epoch 369/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2798\n",
      "\n",
      "Epoch 00369: loss did not improve from 0.26925\n",
      "Epoch 370/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2726\n",
      "\n",
      "Epoch 00370: loss did not improve from 0.26925\n",
      "Epoch 371/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2716\n",
      "\n",
      "Epoch 00371: loss did not improve from 0.26925\n",
      "Epoch 372/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 0.2848\n",
      "\n",
      "Epoch 00372: loss did not improve from 0.26925\n",
      "Epoch 373/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2771\n",
      "\n",
      "Epoch 00373: loss did not improve from 0.26925\n",
      "Epoch 374/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2703\n",
      "\n",
      "Epoch 00374: loss did not improve from 0.26925\n",
      "Epoch 375/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2713\n",
      "\n",
      "Epoch 00375: loss did not improve from 0.26925\n",
      "Epoch 376/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2620\n",
      "\n",
      "Epoch 00376: loss improved from 0.26925 to 0.26196, saving model to RNN_weights.hdf5\n",
      "Epoch 377/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2679\n",
      "\n",
      "Epoch 00377: loss did not improve from 0.26196\n",
      "Epoch 378/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2747\n",
      "\n",
      "Epoch 00378: loss did not improve from 0.26196\n",
      "Epoch 379/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2679\n",
      "\n",
      "Epoch 00379: loss did not improve from 0.26196\n",
      "Epoch 380/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2668\n",
      "\n",
      "Epoch 00380: loss did not improve from 0.26196\n",
      "Epoch 381/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2576\n",
      "\n",
      "Epoch 00381: loss improved from 0.26196 to 0.25756, saving model to RNN_weights.hdf5\n",
      "Epoch 382/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2765\n",
      "\n",
      "Epoch 00382: loss did not improve from 0.25756\n",
      "Epoch 383/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2705\n",
      "\n",
      "Epoch 00383: loss did not improve from 0.25756\n",
      "Epoch 384/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2672\n",
      "\n",
      "Epoch 00384: loss did not improve from 0.25756\n",
      "Epoch 385/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2651\n",
      "\n",
      "Epoch 00385: loss did not improve from 0.25756\n",
      "Epoch 386/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2617\n",
      "\n",
      "Epoch 00386: loss did not improve from 0.25756\n",
      "Epoch 387/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2676\n",
      "\n",
      "Epoch 00387: loss did not improve from 0.25756\n",
      "Epoch 388/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2633\n",
      "\n",
      "Epoch 00388: loss did not improve from 0.25756\n",
      "Epoch 389/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2665\n",
      "\n",
      "Epoch 00389: loss did not improve from 0.25756\n",
      "Epoch 390/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2685\n",
      "\n",
      "Epoch 00390: loss did not improve from 0.25756\n",
      "Epoch 391/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2703\n",
      "\n",
      "Epoch 00391: loss did not improve from 0.25756\n",
      "Epoch 392/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2625\n",
      "\n",
      "Epoch 00392: loss did not improve from 0.25756\n",
      "Epoch 393/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2650\n",
      "\n",
      "Epoch 00393: loss did not improve from 0.25756\n",
      "Epoch 394/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.2598\n",
      "\n",
      "Epoch 00394: loss did not improve from 0.25756\n",
      "Epoch 395/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2622\n",
      "\n",
      "Epoch 00395: loss did not improve from 0.25756\n",
      "Epoch 396/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2582\n",
      "\n",
      "Epoch 00396: loss did not improve from 0.25756\n",
      "Epoch 397/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2696\n",
      "\n",
      "Epoch 00397: loss did not improve from 0.25756\n",
      "Epoch 398/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2566\n",
      "\n",
      "Epoch 00398: loss improved from 0.25756 to 0.25665, saving model to RNN_weights.hdf5\n",
      "Epoch 399/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2575\n",
      "\n",
      "Epoch 00399: loss did not improve from 0.25665\n",
      "Epoch 400/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2543\n",
      "\n",
      "Epoch 00400: loss improved from 0.25665 to 0.25427, saving model to RNN_weights.hdf5\n",
      "Epoch 401/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2612\n",
      "\n",
      "Epoch 00401: loss did not improve from 0.25427\n",
      "Epoch 402/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2627\n",
      "\n",
      "Epoch 00402: loss did not improve from 0.25427\n",
      "Epoch 403/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2527\n",
      "\n",
      "Epoch 00403: loss improved from 0.25427 to 0.25267, saving model to RNN_weights.hdf5\n",
      "Epoch 404/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2554\n",
      "\n",
      "Epoch 00404: loss did not improve from 0.25267\n",
      "Epoch 405/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2576\n",
      "\n",
      "Epoch 00405: loss did not improve from 0.25267\n",
      "Epoch 406/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2651\n",
      "\n",
      "Epoch 00406: loss did not improve from 0.25267\n",
      "Epoch 407/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2587\n",
      "\n",
      "Epoch 00407: loss did not improve from 0.25267\n",
      "Epoch 408/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2576\n",
      "\n",
      "Epoch 00408: loss did not improve from 0.25267\n",
      "Epoch 409/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2580\n",
      "\n",
      "Epoch 00409: loss did not improve from 0.25267\n",
      "Epoch 410/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2441\n",
      "\n",
      "Epoch 00410: loss improved from 0.25267 to 0.24412, saving model to RNN_weights.hdf5\n",
      "Epoch 411/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2457\n",
      "\n",
      "Epoch 00411: loss did not improve from 0.24412\n",
      "Epoch 412/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2530\n",
      "\n",
      "Epoch 00412: loss did not improve from 0.24412\n",
      "Epoch 413/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2550\n",
      "\n",
      "Epoch 00413: loss did not improve from 0.24412\n",
      "Epoch 414/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2515\n",
      "\n",
      "Epoch 00414: loss did not improve from 0.24412\n",
      "Epoch 415/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2547\n",
      "\n",
      "Epoch 00415: loss did not improve from 0.24412\n",
      "Epoch 416/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2530\n",
      "\n",
      "Epoch 00416: loss did not improve from 0.24412\n",
      "Epoch 417/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2563\n",
      "\n",
      "Epoch 00417: loss did not improve from 0.24412\n",
      "Epoch 418/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2486\n",
      "\n",
      "Epoch 00418: loss did not improve from 0.24412\n",
      "Epoch 419/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2518\n",
      "\n",
      "Epoch 00419: loss did not improve from 0.24412\n",
      "Epoch 420/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2593\n",
      "\n",
      "Epoch 00420: loss did not improve from 0.24412\n",
      "Epoch 421/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2464\n",
      "\n",
      "Epoch 00421: loss did not improve from 0.24412\n",
      "Epoch 422/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2489\n",
      "\n",
      "Epoch 00422: loss did not improve from 0.24412\n",
      "Epoch 423/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2444\n",
      "\n",
      "Epoch 00423: loss did not improve from 0.24412\n",
      "Epoch 424/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2448\n",
      "\n",
      "Epoch 00424: loss did not improve from 0.24412\n",
      "Epoch 425/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2485\n",
      "\n",
      "Epoch 00425: loss did not improve from 0.24412\n",
      "Epoch 426/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2515\n",
      "\n",
      "Epoch 00426: loss did not improve from 0.24412\n",
      "Epoch 427/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2451\n",
      "\n",
      "Epoch 00427: loss did not improve from 0.24412\n",
      "Epoch 428/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2502\n",
      "\n",
      "Epoch 00428: loss did not improve from 0.24412\n",
      "Epoch 429/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.2458\n",
      "\n",
      "Epoch 00429: loss did not improve from 0.24412\n",
      "Epoch 430/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2456\n",
      "\n",
      "Epoch 00430: loss did not improve from 0.24412\n",
      "Epoch 431/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2489\n",
      "\n",
      "Epoch 00431: loss did not improve from 0.24412\n",
      "Epoch 432/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2455\n",
      "\n",
      "Epoch 00432: loss did not improve from 0.24412\n",
      "Epoch 433/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2419\n",
      "\n",
      "Epoch 00433: loss improved from 0.24412 to 0.24193, saving model to RNN_weights.hdf5\n",
      "Epoch 434/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2415\n",
      "\n",
      "Epoch 00434: loss improved from 0.24193 to 0.24149, saving model to RNN_weights.hdf5\n",
      "Epoch 435/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2437\n",
      "\n",
      "Epoch 00435: loss did not improve from 0.24149\n",
      "Epoch 436/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2311\n",
      "\n",
      "Epoch 00436: loss improved from 0.24149 to 0.23114, saving model to RNN_weights.hdf5\n",
      "Epoch 437/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2451\n",
      "\n",
      "Epoch 00437: loss did not improve from 0.23114\n",
      "Epoch 438/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2501\n",
      "\n",
      "Epoch 00438: loss did not improve from 0.23114\n",
      "Epoch 439/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2531\n",
      "\n",
      "Epoch 00439: loss did not improve from 0.23114\n",
      "Epoch 440/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2458\n",
      "\n",
      "Epoch 00440: loss did not improve from 0.23114\n",
      "Epoch 441/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2395\n",
      "\n",
      "Epoch 00441: loss did not improve from 0.23114\n",
      "Epoch 442/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2411\n",
      "\n",
      "Epoch 00442: loss did not improve from 0.23114\n",
      "Epoch 443/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2481\n",
      "\n",
      "Epoch 00443: loss did not improve from 0.23114\n",
      "Epoch 444/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2431\n",
      "\n",
      "Epoch 00444: loss did not improve from 0.23114\n",
      "Epoch 445/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2355\n",
      "\n",
      "Epoch 00445: loss did not improve from 0.23114\n",
      "Epoch 446/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2352\n",
      "\n",
      "Epoch 00446: loss did not improve from 0.23114\n",
      "Epoch 447/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2433\n",
      "\n",
      "Epoch 00447: loss did not improve from 0.23114\n",
      "Epoch 448/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2483\n",
      "\n",
      "Epoch 00448: loss did not improve from 0.23114\n",
      "Epoch 449/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2421\n",
      "\n",
      "Epoch 00449: loss did not improve from 0.23114\n",
      "Epoch 450/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2450\n",
      "\n",
      "Epoch 00450: loss did not improve from 0.23114\n",
      "Epoch 451/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2358\n",
      "\n",
      "Epoch 00451: loss did not improve from 0.23114\n",
      "Epoch 452/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2465\n",
      "\n",
      "Epoch 00452: loss did not improve from 0.23114\n",
      "Epoch 453/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2370\n",
      "\n",
      "Epoch 00453: loss did not improve from 0.23114\n",
      "Epoch 454/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2368\n",
      "\n",
      "Epoch 00454: loss did not improve from 0.23114\n",
      "Epoch 455/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2399\n",
      "\n",
      "Epoch 00455: loss did not improve from 0.23114\n",
      "Epoch 456/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2335\n",
      "\n",
      "Epoch 00456: loss did not improve from 0.23114\n",
      "Epoch 457/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2287\n",
      "\n",
      "Epoch 00457: loss improved from 0.23114 to 0.22870, saving model to RNN_weights.hdf5\n",
      "Epoch 458/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2331\n",
      "\n",
      "Epoch 00458: loss did not improve from 0.22870\n",
      "Epoch 459/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2253\n",
      "\n",
      "Epoch 00459: loss improved from 0.22870 to 0.22534, saving model to RNN_weights.hdf5\n",
      "Epoch 460/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2430\n",
      "\n",
      "Epoch 00460: loss did not improve from 0.22534\n",
      "Epoch 461/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2309\n",
      "\n",
      "Epoch 00461: loss did not improve from 0.22534\n",
      "Epoch 462/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2331\n",
      "\n",
      "Epoch 00462: loss did not improve from 0.22534\n",
      "Epoch 463/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2341\n",
      "\n",
      "Epoch 00463: loss did not improve from 0.22534\n",
      "Epoch 464/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2323\n",
      "\n",
      "Epoch 00464: loss did not improve from 0.22534\n",
      "Epoch 465/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2300\n",
      "\n",
      "Epoch 00465: loss did not improve from 0.22534\n",
      "Epoch 466/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2358\n",
      "\n",
      "Epoch 00466: loss did not improve from 0.22534\n",
      "Epoch 467/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2342\n",
      "\n",
      "Epoch 00467: loss did not improve from 0.22534\n",
      "Epoch 468/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2314\n",
      "\n",
      "Epoch 00468: loss did not improve from 0.22534\n",
      "Epoch 469/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2256\n",
      "\n",
      "Epoch 00469: loss did not improve from 0.22534\n",
      "Epoch 470/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2366\n",
      "\n",
      "Epoch 00470: loss did not improve from 0.22534\n",
      "Epoch 471/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2257\n",
      "\n",
      "Epoch 00471: loss did not improve from 0.22534\n",
      "Epoch 472/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2346\n",
      "\n",
      "Epoch 00472: loss did not improve from 0.22534\n",
      "Epoch 473/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2314\n",
      "\n",
      "Epoch 00473: loss did not improve from 0.22534\n",
      "Epoch 474/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2306\n",
      "\n",
      "Epoch 00474: loss did not improve from 0.22534\n",
      "Epoch 475/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2376\n",
      "\n",
      "Epoch 00475: loss did not improve from 0.22534\n",
      "Epoch 476/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2321\n",
      "\n",
      "Epoch 00476: loss did not improve from 0.22534\n",
      "Epoch 477/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2199\n",
      "\n",
      "Epoch 00477: loss improved from 0.22534 to 0.21992, saving model to RNN_weights.hdf5\n",
      "Epoch 478/500\n",
      "39572/39572 [==============================] - 57s 1ms/step - loss: 0.2352\n",
      "\n",
      "Epoch 00478: loss did not improve from 0.21992\n",
      "Epoch 479/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2305\n",
      "\n",
      "Epoch 00479: loss did not improve from 0.21992\n",
      "Epoch 480/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2366\n",
      "\n",
      "Epoch 00480: loss did not improve from 0.21992\n",
      "Epoch 481/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2296\n",
      "\n",
      "Epoch 00481: loss did not improve from 0.21992\n",
      "Epoch 482/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2287\n",
      "\n",
      "Epoch 00482: loss did not improve from 0.21992\n",
      "Epoch 483/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2258\n",
      "\n",
      "Epoch 00483: loss did not improve from 0.21992\n",
      "Epoch 484/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2310\n",
      "\n",
      "Epoch 00484: loss did not improve from 0.21992\n",
      "Epoch 485/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2326\n",
      "\n",
      "Epoch 00485: loss did not improve from 0.21992\n",
      "Epoch 486/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2308\n",
      "\n",
      "Epoch 00486: loss did not improve from 0.21992\n",
      "Epoch 487/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2241\n",
      "\n",
      "Epoch 00487: loss did not improve from 0.21992\n",
      "Epoch 488/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2171\n",
      "\n",
      "Epoch 00488: loss improved from 0.21992 to 0.21708, saving model to RNN_weights.hdf5\n",
      "Epoch 489/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2267\n",
      "\n",
      "Epoch 00489: loss did not improve from 0.21708\n",
      "Epoch 490/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2353\n",
      "\n",
      "Epoch 00490: loss did not improve from 0.21708\n",
      "Epoch 491/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2314\n",
      "\n",
      "Epoch 00491: loss did not improve from 0.21708\n",
      "Epoch 492/500\n",
      "39572/39572 [==============================] - 58s 1ms/step - loss: 0.2311\n",
      "\n",
      "Epoch 00492: loss did not improve from 0.21708\n",
      "Epoch 493/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2171\n",
      "\n",
      "Epoch 00493: loss improved from 0.21708 to 0.21707, saving model to RNN_weights.hdf5\n",
      "Epoch 494/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2277\n",
      "\n",
      "Epoch 00494: loss did not improve from 0.21707\n",
      "Epoch 495/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2310\n",
      "\n",
      "Epoch 00495: loss did not improve from 0.21707\n",
      "Epoch 496/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2239\n",
      "\n",
      "Epoch 00496: loss did not improve from 0.21707\n",
      "Epoch 497/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2321\n",
      "\n",
      "Epoch 00497: loss did not improve from 0.21707\n",
      "Epoch 498/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2180\n",
      "\n",
      "Epoch 00498: loss did not improve from 0.21707\n",
      "Epoch 499/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2272\n",
      "\n",
      "Epoch 00499: loss did not improve from 0.21707\n",
      "Epoch 500/500\n",
      "39572/39572 [==============================] - 56s 1ms/step - loss: 0.2267\n",
      "\n",
      "Epoch 00500: loss did not improve from 0.21707\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=500, batch_size=256, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history', 'wb') as f:\n",
    "     pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history', 'rb') as f:\n",
    "     history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pre-trained weights\n",
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the graph, we can see the gradual decrease of cross-entropy loss, which is a good sign. There still exists a little downward slope, however it requires much more time to train and tuning in hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a dictionary that will convert the RNN output in numbers back to characters \n",
    "num_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:\n",
      "\"  дальше остановок видать пока нам ног сломит вражий костолом живём умрём удобрим гору собой став её  \"\n"
     ]
    }
   ],
   "source": [
    "#Provide our model with random seed character from which it will generate a sequence of characters\n",
    "start = np.random.randint(0, len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed:\")\n",
    "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the generated verse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "углём недобром городе рабом бунтарём это круговорот природы червяков доест орёл червяки орла всё переплетено внедрим пол"
     ]
    }
   ],
   "source": [
    "#Finally, generate rap\n",
    "for i in range(120):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "\n",
    "    sys.stdout.write(result)\n",
    "\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, our model generate new verses based on the learned vocabulary from 20 Oxxxymiron songs. Even though the model is not so good at constructing sentences yet as the human brain does, that is already a good prerequisite to further depvelopment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
